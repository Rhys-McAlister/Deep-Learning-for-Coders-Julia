[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep learning for coders julia",
    "section": "",
    "text": "Preface\nThis book is my work in progress interpretation of the excellent Practical Deep Learning for Coders book written by Jeremy Howard and Sylvain Gugger. This book is being rewritten as a way of better learning the material in addition to the Julia language as well as providing a resource to those who wish to explore deep learning in Julia.\n\n\n\n\n\n\nWarning\n\n\n\nForewarning, there will be typos and errors in the code as I will be publicly updating this book as I work on it, thanks for understanding!"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Chapter_4.html#pixels-the-foundations-of-computer-vision",
    "href": "Chapter_4.html#pixels-the-foundations-of-computer-vision",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.1 Pixels: The Foundations of Computer Vision",
    "text": "2.1 Pixels: The Foundations of Computer Vision\nIn an effort to understand the internals of computer vision models, we first begin by discussing how computers handle images. The dataset used to illustrate this concept will be MNIST.\nIn the original book, the FastAI vision library will download the MNIST dataset to your computer and place the images into separate folders depending upon the identity of the image and its position in the train or validation sets. For simplicity here we use the MLDatasets package instead.\nBelow we can see a visualisation of two examples of the images found within these datasets. The images are either a handwritten three or a seven.\n\ndataset = MLDatasets.MNIST(:train)\n\n\nthree_features = (dataset.features[:,:,dataset.targets .== 3]) / 255\nseven_features = (dataset.features[:,:,dataset.targets .== 7]) / 255\n\n\nstacked_sevens = permutedims(seven_features, [1, 2, 3])\nstacked_threes = permutedims(three_features, [2, 1, 3])\n\n\n\n\nPlots.heatmap(stacked_sevens[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\nPlots.heatmap(seven_features[:,:,9])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nIn a computer everything is represented using numbers and images are no exception. Here we see a small section of the image of a three. Each of the numbers within this array is representative of a pixel within the image.\n\nthree_features[4:10,4:10,1]\n\n7×7 Matrix{Float32}:\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.000661284  0.00273741  0.00167628  6.15148f-5"
  },
  {
    "objectID": "Chapter_4.html#first-try-pixel-similarity",
    "href": "Chapter_4.html#first-try-pixel-similarity",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.2 First try: Pixel Similarity",
    "text": "2.2 First try: Pixel Similarity\nFor a first approach to solving the issue of distinguishing between a photo of a three or a seven, we begin by calculating the average pixel value of every pixel for both a 3 and a 7. This provides us two group averages that we can consider to be the ‘ideal’ 3 and 7. Then a comparsion between a given image and these two averages will help us classify said image.\n\n\n\n\n\n\nBaseline\n\n\n\nA baseline model is a simple model that you are confident will perform reasonably well. Ideally these models should be easy to implement and test such that we have the ability to reference the performance of our new and more complex models against. This is an important place to begin as without a baseline in place we can’t really judge if our new and fancy models are actually performing that well.\n\n\nLet’s begin by calculating the average of the pixel values for our 3s and 7s.\nFor every pixel in an image, we would like to calculate the average value of that pixel over all the images of our 3s or 7s. If we were beginning with single images we would need to combine all of our images into a single three-dimensional tensor. Fortunately, the MLDatasets library provides us with a tensor that is already in this format.\nBelow we can see what the ‘average’ 3 and 7 images look like.\n\nmean3 = mean(stacked_threes, dims=3)\nmean7 = mean(stacked_sevens, dims=3)\n\nPlots.heatmap(mean3[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\nPlots.heatmap(mean7[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nHere, we select a random single image from the dataset to serve as a representative image to test our model against.\n\na_3 = stacked_threes[:, :, 20]\na_7 = stacked_sevens[:, :, 20]\n\nPlots.heatmap(a_3)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nSo how do we quantify the distance of a given image from our ideal 3? There are two ways we can approach this issue, we can take the mean of the absolute value of the differences between each pixel, this is referred to as the mean absolute difference (L1 norm). Alternatively, we could take the mean of the squared differences between each pixel and then apply a square root (to undo the squaring). This is called the root mean squared error (RMSE or L2 norm).\nBelow we see two functions that accept two tensors and calculate either the mean absolute distance or root mean squared error.\n\n\"Calculates the average absolute distance between two tensors\"\nfunction mean_abs_mnist_distance(a, b)\n    return mean(abs.(a .- b), dims=(1,2))\nend\n\n\"Calculates the mean of the squared distance between two tensors\"\nfunction sqrt_mean_mnist_distance(a, b)\n    return sqrt(mean((a .- b).^2))\nend\n\ndist_3_abs = mean_abs_mnist_distance(a_3, mean3)\ndist_7_abs = mean_abs_mnist_distance(a_7, mean3)\n\nprintln(\"Distance from 3: \", dist_3_abs)\nprintln(\"Distance from 7: \", dist_7_abs)\n\nDistance from 3: [\n\n\n0.00065970985;;;]\nDistance from 7: [0.00071201497;;;]\n\n\n\ndist_3_sqrt = sqrt_mean_mnist_distance(a_3, mean3)\ndist_7_sqrt = sqrt_mean_mnist_distance(a_7, mean3)\n\nprintln(\"Distance from 3: \", dist_3_sqrt)\nprintln(\"Distance from 7: \", dist_7_sqrt)\n\nDistance from 3: 0.0011778519\nDistance from 7: 0.0012536361\n\n\nFortunately, Flux provides us with both of this loss functions already and they can be called as seen below.\n\nFlux.Losses.mae(a_3, mean3)\n\nsqrt(Flux.Losses.mse(a_3, mean3))\n\n0.0011778519f0"
  },
  {
    "objectID": "Chapter_4.html#computing-metrics-using-broadcasting",
    "href": "Chapter_4.html#computing-metrics-using-broadcasting",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.3 Computing Metrics Using Broadcasting",
    "text": "2.3 Computing Metrics Using Broadcasting\n\n\n\n\n\n\nNote\n\n\n\nA metric is a numeric value calculated based upon our models predictions and the correct labels in our dataset, that tells us how well our model is performing.\n\n\nAlthough both mean squared error and mean absolute error could very well serve as our metrics of choice, these two values are not very interpretable to most people. Thus, the use of accuracy as a metric in the domain of classification models is more often the norm.\nNormally, the metric is calculated based on the performance of our model on the validation dataset, however in our pixel similarity model there is no trained component thus there isn’t really a risk of overfitting here. To keep with our conventions we will still use a validation set regardless in this problem.\nTo create a validation set, we remove a portion of the data from training entirely, such that the model doesn’t have an opportunity to see this data. Fortunately, the creators of the MNIST dataset have preallocated a portion of the images into training and validation sets and the MLDatasets library has presented this dataset accordingly. It is important to note that the same prepartation steps we applied to the training data has been applied to the validation data.\n\nvalid = MLDatasets.MNIST(:test)\nvalid_three_features = (valid.features[:,:,valid.targets .== 3]) / 255\nvalid_seven_features = (valid.features[:,:,valid.targets .== 7]) / 255\nvalid_seven_features = permutedims(valid_seven_features, [1, 2, 3])\nvalid_three_features = permutedims(valid_three_features, [2, 1, 3])\n\n28×28×1010 Array{Float32, 3}:\n[:, :, 1] =\n 0.0  0.0  0.0  0.0  0.0  0.0          …  0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.000184544  …  0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00204537      0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00155325      0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00278354      0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00392157      0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00287582   …  0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.00224529      0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0014456       0.0          0.0  0.0  0.0\n ⋮                        ⋮            ⋱               ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.00110727   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.00293733   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.00222991   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0          …  0.00222991   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.000292195  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0          …  0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0             0.0          0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n ⋮                        ⋮         ⋱                      ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n[:, :, 3] =\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.000984237     0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.000292195     0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n ⋮                        ⋮                 ⋱                 ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n\n;;; … \n\n[:, :, 1008] =\n 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0030296   0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.00372165  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.00135333  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n ⋮                               ⋱                   ⋮         \n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.00241446  …  0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.00378316     0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.00152249     0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n\n[:, :, 1009] =\n 0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n ⋮                        ⋮    ⋱                      ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n[:, :, 1010] =\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.000891965     0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.00101499      0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n ⋮                        ⋮                 ⋱                 ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.00286044      0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.00329104   …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.000984237     0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0          …  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0             0.0  0.0  0.0  0.0  0.0  0.0\n\n\n\nfunction prepare_data(dataset)\n    # select 3s and 7s\n    three_feats = (dataset.features[:,:,dataset.targets .== 3]) / 255\n    seven_feats = (dataset.features[:,:,dataset.targets .== 7]) / 255\n\n    # rearrange dimensions\n    three_feats = permutedims(three_feats, [1, 2, 3])\n    seven_feats = permutedims(seven_feats, [2, 1, 3])\n    return three_feats, seven_feats\nend\n\nprepare_data (generic function with 1 method)\n\n\n\ntft, sft = prepare_data(valid)\n\nsize(tft) == size(valid_three_features)\n\ntrue\n\n\nOur aim now is to create a function called is_3 that will determine if some image is a 3 or a 7. It will accomplish this by determining which of our two average 3 and 7 images this selected image is closer to. To judge this distance between images we will begin by defining a function that quantifies the distance between two images using the mean absolute error.\n\nfunction mnist_distance(a, b)\n    return mean(abs.(a .- b), dims=(1,2))\nend\n\nmnist_distance (generic function with 1 method)\n\n\n\nfunction is3(x)\n    return mnist_distance(x, mean3) .&lt; mnist_distance(x, mean7)\nend\n\nis3 (generic function with 1 method)\n\n\n\naccuracy_3s = mean(is3(valid_three_features))\naccuracy_7s = 1 - mean(is3(valid_seven_features))\n\nprintln(\"Accuracy of 3s: \", accuracy_3s)\nprintln(\"Accuracy of 7s: \", accuracy_7s)\n\nAccuracy of 3s: 0.9881188118811881\nAccuracy of 7s: 0.9970817120622568"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]