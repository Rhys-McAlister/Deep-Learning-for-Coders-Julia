[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep learning for coders julia",
    "section": "",
    "text": "Preface\nThis book is my work in progress interpretation of the excellent Practical Deep Learning for Coders book written by Jeremy Howard and Sylvain Gugger. This book is being rewritten as a way of better learning the material in addition to the Julia language as well as providing a resource to those who wish to explore deep learning in Julia.\n\n\n\n\n\n\nWarning\n\n\n\nForewarning, there will be typos and errors in the code as I will be publicly updating this book as I work on it, thanks for understanding!"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Chapter_4.html#pixels-the-foundations-of-computer-vision",
    "href": "Chapter_4.html#pixels-the-foundations-of-computer-vision",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.1 Pixels: The Foundations of Computer Vision",
    "text": "2.1 Pixels: The Foundations of Computer Vision\nIn an effort to understand the internals of computer vision models, we first begin by discussing how computers handle images. The dataset used to illustrate this concept will be MNIST.\nIn the original book, the FastAI vision library will download the MNIST dataset to your computer and place the images into separate folders depending upon the identity of the image and its position in the train or validation sets. For simplicity here we use the MLDatasets package instead.\nBelow we can see a visualisation of two examples of the images found within these datasets. The images are either a handwritten three or a seven.\n\ndataset = MLDatasets.MNIST(:train)\nvalid = MLDatasets.MNIST(:test)\n\nthree_features = (dataset.features[:,:,dataset.targets .== 3]) / 255\nseven_features = (dataset.features[:,:,dataset.targets .== 7]) / 255\nvalid_three_features = (valid.features[:,:,valid.targets .== 3]) / 255\nvalid_seven_features = (valid.features[:,:,valid.targets .== 7]) / 255\n\nstacked_sevens = permutedims(seven_features, [1, 2, 3])\nstacked_threes = permutedims(three_features, [2, 1, 3])\n\nvalid_seven_features = permutedims(valid_seven_features, [1, 2, 3])\nvalid_three_features = permutedims(valid_three_features, [2, 1, 3])\n\n\nPlots.heatmap(stacked_sevens[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\nPlots.heatmap(seven_features[:,:,9])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nIn a computer everything is represented using numbers and images are no exception. Here we see a small section of the image of a three. Each of the numbers within this array is representative of a pixel within the image.\n\nthree_features[4:10,4:10,1]\n\n7×7 Matrix{Float32}:\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.0          0.0         0.0         0.0\n 0.0  0.0  0.0  0.000661284  0.00273741  0.00167628  6.15148f-5"
  },
  {
    "objectID": "Chapter_4.html#first-try-pixel-similarity",
    "href": "Chapter_4.html#first-try-pixel-similarity",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.2 First try: Pixel Similarity",
    "text": "2.2 First try: Pixel Similarity\nFor a first approach to solving the issue of distinguishing between a photo of a three or a seven, we begin by calculating the average pixel value of every pixel for both a 3 and a 7. This provides us two group averages that we can consider to be the ‘ideal’ 3 and 7. Then a comparsion between a given image and these two averages will help us classify said image.\n\n\n\n\n\n\nBaseline\n\n\n\nA baseline model is a simple model that you are confident will perform reasonably well. Ideally these models should be easy to implement and test such that we have the ability to reference the performance of our new and more complex models against. This is an important place to begin as without a baseline in place we can’t really judge if our new and fancy models are actually performing that well.\n\n\nLet’s begin by calculating the average of the pixel values for our 3s and 7s.\nFor every pixel in an image, we would like to calculate the average value of that pixel over all the images of our 3s or 7s. If we were beginning with single images we would need to combine all of our images into a single three-dimensional tensor. Fortunately, the MLDatasets library provides us with a tensor that is already in this format.\nBelow we can see what the ‘average’ 3 and 7 images look like.\n\nmean3 = mean(stacked_threes, dims=3)\nmean7 = mean(stacked_sevens, dims=3)\n\nPlots.heatmap(mean3[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\nPlots.heatmap(mean7[:,:,1])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nHere, we select a random single image from the dataset to serve as a representative image to test our model against.\n\na_3 = stacked_threes[:, :, 20]\na_7 = stacked_sevens[:, :, 20]\n\nPlots.heatmap(a_3)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nSo how do we quantify the distance of a given image from our ideal 3? There are two ways we can approach this issue, we can take the mean of the absolute value of the differences between each pixel, this is referred to as the mean absolute difference (L1 norm). Alternatively, we could take the mean of the squared differences between each pixel and then apply a square root (to undo the squaring). This is called the root mean squared error (RMSE or L2 norm).\n\n\"Calculates the average absolute distance between two tensors\"\nfunction mean_abs_mnist_distance(a, b)\n    return mean(abs.(a .- b), dims=(1,2))\nend\n\n\"Calculates the mean of the squared distance between two tensors\"\nfunction sqrt_mean_mnist_distance(a, b)\n    return sqrt(mean((a .- b).^2))\nend\n\ndist_3_abs = mean_abs_mnist_distance(a_3, mean3)\ndist_7_abs = mean_abs_mnist_distance(a_7, mean3)\n\nprintln(\"Distance from 3: \", dist_3_abs)\nprintln(\"Distance from 7: \", dist_7_abs)\n\nDistance from 3: [\n\n\n0.00065970985;;;]\nDistance from 7: [0.00071201497;;;]\n\n\n\ndist_3_sqrt = sqrt_mean_mnist_distance(a_3, mean3)\ndist_7_sqrt = sqrt_mean_mnist_distance(a_7, mean3)\n\nprintln(\"Distance from 3: \", dist_3_sqrt)\nprintln(\"Distance from 7: \", dist_7_sqrt)\n\nDistance from 3: 0.0011778519\nDistance from 7: 0.0012536361\n\n\nFortunately, Flux provides us with both of this loss functions already and they can be called as seen below.\n\nFlux.Losses.mae(a_3, mean3)\n\nsqrt(Flux.Losses.mse(a_3, mean3))\n\n0.0011778519f0"
  },
  {
    "objectID": "Chapter_4.html#computing-metrics-using-broadcasting",
    "href": "Chapter_4.html#computing-metrics-using-broadcasting",
    "title": "2  Under the Hood: Training a Digit Classifier",
    "section": "2.3 Computing Metrics Using Broadcasting",
    "text": "2.3 Computing Metrics Using Broadcasting\n\nfunction mnist_distance(a, b)\n    return mean(abs.(a .- b), dims=(1,2))\nend\n\nmnist_distance (generic function with 1 method)\n\n\n\nfunction is3(x)\n    return mnist_distance(x, mean3) .&lt; mnist_distance(x, mean7)\nend\n\nis3 (generic function with 1 method)\n\n\n\naccuracy_3s = mean(is3(valid_three_features))\naccuracy_7s = 1 - mean(is3(valid_seven_features))\n\nprintln(\"Accuracy of 3s: \", accuracy_3s)\nprintln(\"Accuracy of 7s: \", accuracy_7s)\n\nAccuracy of 3s: 0.9881188118811881\nAccuracy of 7s: 0.9970817120622568"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]