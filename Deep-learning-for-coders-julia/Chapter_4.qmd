# Under the Hood: Training a Digit Classifier

```{julia}
#| echo: false
#| warning: false
#| error: false
#| include: false
import Pkg; Pkg.activate(".")
using MLDatasets
using Images
using Plots
using Statistics
using Flux
```

This chapter utilises the topic of computer vision as a vehicle for introducing a number of fundamental tools and concepts for deep learning.

These tools and concepts include:

-   Roles of arrays and tensors and how broadcasting can be used to operate on these structures.
-   Stochastic gradient descent and how it can be used to train a model.
-   Choosing appropriate loss functions for a basic classification task.
-   The role of mini-batches in training a model.
-   The math that a basic neural network is utilising.

## Pixels: The Foundations of Computer Vision

In an effort to understand the internals of computer vision models, we first begin by discussing how computers handle images. The dataset used to illustrate this concept will be [MNIST](https://en.wikipedia.org/wiki/MNIST_database "MNIST dataset").

In the original book, the FastAI vision library will download the MNIST dataset to your computer and place the images into separate folders depending upon the identity of the image and its position in the train or validation sets. For simplicity here we use the `MLDatasets` package instead.

Below we can see a visualisation of two examples of the images found within these datasets. The images are either a handwritten three or a seven.

```{julia}


dataset = MLDatasets.MNIST(:train)
valid = MLDatasets.MNIST(:test)

three_features = (dataset.features[:,:,dataset.targets .== 3]) / 255
seven_features = (dataset.features[:,:,dataset.targets .== 7]) / 255
valid_three_features = (valid.features[:,:,valid.targets .== 3]) / 255
valid_seven_features = (valid.features[:,:,valid.targets .== 7]) / 255

stacked_sevens = permutedims(seven_features, [1, 2, 3])
stacked_threes = permutedims(three_features, [2, 1, 3])

valid_seven_features = permutedims(valid_seven_features, [1, 2, 3])
valid_three_features = permutedims(valid_three_features, [2, 1, 3])


Plots.heatmap(stacked_sevens[:,:,1])
```

```{julia}
Plots.heatmap(seven_features[:,:,9])
```

In a computer everything is represented using numbers and images are no exception. Here we see a small section of the image of a three. Each of the numbers within this array is representative of a pixel within the image.

```{julia}
three_features[4:10,4:10,1]
```

## First try: Pixel Similarity

For a first approach to solving the issue of distinguishing between a photo of a three or a seven, we begin by calculating the average pixel value of every pixel for both a 3 and a 7. This provides us two group averages that we can consider to be the 'ideal' 3 and 7. Then a comparsion between a given image and these two averages will help us classify said image.

::: callout-tip
## Baseline

A baseline model is a simple model that you are confident will perform reasonably well. Ideally these models should be easy to implement and test such that we have the ability to reference the performance of our new and more complex models against. This is an important place to begin as without a baseline in place we can't really judge if our new and fancy models are actually performing that well.
:::

Let's begin by calculating the average of the pixel values for our 3s and 7s.

For every pixel in an image, we would like to calculate the average value of that pixel over all the images of our 3s or 7s. If we were beginning with single images we would need to combine all of our images into a single three-dimensional tensor. Fortunately, the `MLDatasets` library provides us with a tensor that is already in this format.

Below we can see what the 'average' 3 and 7 images look like.

```{julia}
mean3 = mean(stacked_threes, dims=3)
mean7 = mean(stacked_sevens, dims=3)

Plots.heatmap(mean3[:,:,1])
```

```{julia}
Plots.heatmap(mean7[:,:,1])
```

Here, we select a random single image from the dataset to serve as a representative image to test our model against.

```{julia}
a_3 = stacked_threes[:, :, 20]
a_7 = stacked_sevens[:, :, 20]

Plots.heatmap(a_3)
```

So how do we quantify the distance of a given image from our ideal 3? There are two ways we can approach this issue, we can take the mean of the absolute value of the differences between each pixel, this is referred to as the mean absolute difference (L1 norm). Alternatively, we could take the mean of the squared differences between each pixel and then apply a square root (to undo the squaring). This is called the root mean squared error (RMSE or L2 norm).

```{julia}
"Calculates the average absolute distance between two tensors"
function mean_abs_mnist_distance(a, b)
    return mean(abs.(a .- b), dims=(1,2))
end

"Calculates the mean of the squared distance between two tensors"
function sqrt_mean_mnist_distance(a, b)
    return sqrt(mean((a .- b).^2))
end

dist_3_abs = mean_abs_mnist_distance(a_3, mean3)
dist_7_abs = mean_abs_mnist_distance(a_7, mean3)

println("Distance from 3: ", dist_3_abs)
println("Distance from 7: ", dist_7_abs)
```

```{julia}
dist_3_sqrt = sqrt_mean_mnist_distance(a_3, mean3)
dist_7_sqrt = sqrt_mean_mnist_distance(a_7, mean3)

println("Distance from 3: ", dist_3_sqrt)
println("Distance from 7: ", dist_7_sqrt)
```

Fortunately, Flux provides us with both of this loss functions already and they can be called as seen below.

```{julia}
Flux.Losses.mae(a_3, mean3)

sqrt(Flux.Losses.mse(a_3, mean3))
```

## Computing Metrics Using Broadcasting

```{julia}
function mnist_distance(a, b)
    return mean(abs.(a .- b), dims=(1,2))
end
```

```{julia}
function is3(x)
    return mnist_distance(x, mean3) .< mnist_distance(x, mean7)
end
```

```{julia}
accuracy_3s = mean(is3(valid_three_features))
accuracy_7s = 1 - mean(is3(valid_seven_features))

println("Accuracy of 3s: ", accuracy_3s)
println("Accuracy of 7s: ", accuracy_7s)
```

