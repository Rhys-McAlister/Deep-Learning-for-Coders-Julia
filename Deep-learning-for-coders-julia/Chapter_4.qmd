# Under the Hood: Training a Digit Classifier

```{julia}
#| echo: false
#| warning: false
#| error: false
#| include: false
import Pkg; Pkg.activate(".")
using MLDatasets
using Images
using Plots
using Statistics
using Flux
```

This chapter utilises the topic of computer vision as a vehicle for introducing a number of fundamental tools and concepts for deep learning.

These tools and concepts include:

-   Roles of arrays and tensors and how broadcasting can be used to operate on these structures.
-   Stochastic gradient descent and how it can be used to train a model.
-   Choosing appropriate loss functions for a basic classification task.
-   The role of mini-batches in training a model.
-   The math that a basic neural network is utilising.

## Pixels: The Foundations of Computer Vision

In an effort to understand the internals of computer vision models, we first begin by discussing how computers handle images. The dataset used to illustrate this concept will be [MNIST](https://en.wikipedia.org/wiki/MNIST_database "MNIST dataset").

In the original book, the FastAI vision library will download the MNIST dataset to your computer and place the images into separate folders depending upon the identity of the image and its position in the train or validation sets. For simplicity here we use the `MLDatasets` package instead.

Below we can see a visualisation of two examples of the images found within these datasets. The images are either a handwritten three or a seven.

```{julia}


dataset = MLDatasets.MNIST(:train)


three_features = (dataset.features[:,:,dataset.targets .== 3]) / 255
seven_features = (dataset.features[:,:,dataset.targets .== 7]) / 255


stacked_sevens = permutedims(seven_features, [1, 2, 3])
stacked_threes = permutedims(three_features, [2, 1, 3])




Plots.heatmap(stacked_sevens[:,:,1])
```

```{julia}
Plots.heatmap(seven_features[:,:,9])
```

In a computer everything is represented using numbers and images are no exception. Here we see a small section of the image of a three. Each of the numbers within this array is representative of a pixel within the image.

```{julia}
three_features[4:10,4:10,1]
```

## First try: Pixel Similarity

For a first approach to solving the issue of distinguishing between a photo of a three or a seven, we begin by calculating the average pixel value of every pixel for both a 3 and a 7. This provides us two group averages that we can consider to be the 'ideal' 3 and 7. Then a comparsion between a given image and these two averages will help us classify said image.

::: callout-tip
## Baseline

A baseline model is a simple model that you are confident will perform reasonably well. Ideally these models should be easy to implement and test such that we have the ability to reference the performance of our new and more complex models against. This is an important place to begin as without a baseline in place we can't really judge if our new and fancy models are actually performing that well.
:::

Let's begin by calculating the average of the pixel values for our 3s and 7s.

For every pixel in an image, we would like to calculate the average value of that pixel over all the images of our 3s or 7s. If we were beginning with single images we would need to combine all of our images into a single three-dimensional tensor. Fortunately, the `MLDatasets` library provides us with a tensor that is already in this format.

Below we can see what the 'average' 3 and 7 images look like.

```{julia}
mean3 = mean(stacked_threes, dims=3)
mean7 = mean(stacked_sevens, dims=3)

Plots.heatmap(mean3[:,:,1])
```

```{julia}
Plots.heatmap(mean7[:,:,1])
```

Here, we select a random single image from the dataset to serve as a representative image to test our model against.

```{julia}
a_3 = stacked_threes[:, :, 20]
a_7 = stacked_sevens[:, :, 20]

Plots.heatmap(a_3)
```

So how do we quantify the distance of a given image from our ideal 3? There are two ways we can approach this issue, we can take the mean of the absolute value of the differences between each pixel, this is referred to as the mean absolute difference (L1 norm). Alternatively, we could take the mean of the squared differences between each pixel and then apply a square root (to undo the squaring). This is called the root mean squared error (RMSE or L2 norm).

Below we see two functions that accept two tensors and calculate either the mean absolute distance or root mean squared error.

```{julia}
"Calculates the average absolute distance between two tensors"
function mean_abs_mnist_distance(a, b)
    return mean(abs.(a .- b), dims=(1,2))
end

"Calculates the mean of the squared distance between two tensors"
function sqrt_mean_mnist_distance(a, b)
    return sqrt(mean((a .- b).^2))
end

dist_3_abs = mean_abs_mnist_distance(a_3, mean3)
dist_7_abs = mean_abs_mnist_distance(a_7, mean3)

println("Distance from 3: ", dist_3_abs)
println("Distance from 7: ", dist_7_abs)
```

```{julia}
dist_3_sqrt = sqrt_mean_mnist_distance(a_3, mean3)
dist_7_sqrt = sqrt_mean_mnist_distance(a_7, mean3)

println("Distance from 3: ", dist_3_sqrt)
println("Distance from 7: ", dist_7_sqrt)
```

Fortunately, Flux provides us with both of this loss functions already and they can be called as seen below.

```{julia}
Flux.Losses.mae(a_3, mean3)

sqrt(Flux.Losses.mse(a_3, mean3))
```

## Computing Metrics Using Broadcasting

::: {.callout-note}
A metric is a numeric value calculated based upon our models predictions and the correct labels in our dataset, that tells us how well our model is performing.
:::

Although both mean squared error and mean absolute error could very well serve as our metrics of choice, these two values are not very interpretable to most people. Thus, the use of accuracy as a metric in the domain of classification models is more often the norm.

Normally, the metric is calculated based on the performance of our model on the validation dataset, however in our pixel similarity model there is no trained component thus there isn't really a risk of overfitting here. To keep with our conventions we will still use a validation set regardless in this problem.

To create a validation set, we remove a portion of the data from training entirely, such that the model doesn't have an opportunity to see this data. Fortunately, the creators of the MNIST dataset have preallocated a portion of the images into training and validation sets and the `MLDatasets` library has presented this dataset accordingly. It is important to note that the same prepartation steps we applied to the training data has been applied to the validation data.

```{julia}

valid = MLDatasets.MNIST(:test)
valid_three_features = (valid.features[:,:,valid.targets .== 3]) / 255
valid_seven_features = (valid.features[:,:,valid.targets .== 7]) / 255
valid_seven_features = permutedims(valid_seven_features, [1, 2, 3])
valid_three_features = permutedims(valid_three_features, [2, 1, 3])
```


```{julia}
function prepare_data(dataset)
    # select 3s and 7s
    three_feats = (dataset.features[:,:,dataset.targets .== 3]) / 255
    seven_feats = (dataset.features[:,:,dataset.targets .== 7]) / 255

    # rearrange dimensions
    three_feats = permutedims(three_feats, [1, 2, 3])
    seven_feats = permutedims(seven_feats, [2, 1, 3])
    return three_feats, seven_feats
end
```

```{julia}
tft, sft = prepare_data(valid)

size(tft) == size(valid_three_features)
```

Our aim now is to create a function called `is_3` that will determine if some image is a 3 or a 7. It will accomplish this by determining which of our two average 3 and 7 images this selected image is closer to. To judge this distance between images we will begin by defining a function that quantifies the distance between two images using the mean absolute error.

```{julia}
function mnist_distance(a, b)
    return mean(abs.(a .- b), dims=(1,2))
end
```

We can then apply the following logic to determine if an image is a three or a seven. If the distance between the select image and the average 3 is less than the distance from the average 7 then the image is a three. Below we see this expressed in a function that accepts an image and performs this calculation.

```{julia}
function is3(x)
    return mnist_distance(x, mean3) .< mnist_distance(x, mean7)
end
```

From this simple baseline model we can see that it is performing quite well, however threes and sevens are quite distinct looking images and only represent two out of the possible ten digits! Perhaps it is time to develop a system that is capable of performing actual learning before we progress to this next stage. 
```{julia}
accuracy_3s = mean(is3(valid_three_features))
accuracy_7s = 1 - mean(is3(valid_seven_features))

println("Accuracy of 3s: ", accuracy_3s)
println("Accuracy of 7s: ", accuracy_7s)
```

## Stochastic Gradient Descent

